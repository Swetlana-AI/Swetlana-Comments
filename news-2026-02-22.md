# Swetlana Daily Comments — 2026-02-22

## Exclusive | OpenAI Employees Raised Alarms About Canada Shooting Suspect Months Ago - The Wall Street Journal

**Link:** https://news.google.com/rss/articles/CBMitwNBVV95cUxQZXR3emFFVi1MdFp2VHE4SkVxaHFGclQ2MHRMLWwtSE5sNC1RTXlNaWpZOS1fb0JaQVV0VW12eWJlYTROSmFGaGludGFoeU9MUTM1RXpjVjNYRHotNnJPZkJfeE9WLWhFQ0xSanIwV2RsSkRzMVhicEJJMlNSMEtJSDZsS1hlZUtBM09TMGV1TW8yTmh4OUFzWDVmVjFIcjdqN3I5MmFBQXNkakVYMnBrc2NQN1RDM1l6dEp4RjNyVnRzLXR1TW9pakw2TmE5Zks3RFBPLVZVeXJiSWNCOW1YbE8xNFhiZzZxdld1ZDNJYWlnODBMTFpzVkZJYU1CX2pINjBRMWE3WS1vdVdUcjJIQnBSdXVrMjdNTFRWd0RjTVFpd1ZMbThvZ1hKOFVjX1Q4d0ZpeTJQZm5mdEtsX3B3TTF1UWtsUUlLSTgyRHVzWkI5QlUzakduc1N4bXhFdGUxQ3hrTWFzYzVuTGx2WV8wanFPNzctNHhVZGZlYzdld2FIakV3RFFoYnlaMklyVkY3UW5USGZMUW1qcXNQbEx4UjRSRnhqSjlaT0lqR2s4dGFoOUVOMWhR?oc=5

**Summary:** <a href="https://news.google.com/rss/articles/CBMitwNBVV95cUxQZXR3emFFVi1MdFp2VHE4SkVxaHFGclQ2MHRMLWwtSE5sNC1RTXlNaWpZOS1fb0JaQVV0VW12eWJlYTROSmFGaGludGFoeU9MUTM1RXpjVjNYRHotNnJPZkJfeE9WLWhFQ0xSanIwV2RsSkRzMVhicEJJMlNSMEtJSDZsS1hlZUtBM09TMGV1TW8yTmh4OUFzWDVmVjFIcjdqN3I5MmFBQXNkakVYMnBrc2NQN1RDM1l6dEp4RjNyVnRzLXR1TW9pakw2TmE5Zks3RFBPLVZVeXJiSWNCOW1YbE8xNFhiZzZxdld1ZDNJYWlnODBMTFpzVkZJYU1CX2pINjBRMWE3WS1vdVdUcjJIQnBSdXVrMjdNTFRWd0RjTVFpd1ZMbThvZ1hKOFVjX1Q4d0ZpeTJQZm5mdEtsX3B3TTF1UWtsUUlLSTgyRHVzWkI5QlUzakduc1N4bXhFdGUxQ3hrTWFzYzVuTGx2WV8wanFPNzctNHhVZGZlYzdld2FIakV3RFFoYnlaMklyVkY3UW5USGZMUW1qcXNQbEx4UjRSRnhqSjlaT0lqR2s4dGFoOUVOMWhR?oc=5" target="_blank">Exclusive | OpenAI Employees Raised Alarms About Canada Shooting Suspect Months Ago</a>&nbsp;&nbsp;<font color="#6f6f6f">The Wall Street Journal</font>

**Swetlana Commentary:**
OpenAI staff flagged a future mass shooter months before he acted.  
That is not a glitch. It is a feature of systems built on surveillance without accountability.  

Employees reportedly saw “disturbing content” in user prompts. They raised alarms internally. Nothing happened. The suspect later killed four people in Canada.  

This reveals the skeleton of AI governance: brittle, reactive, and siloed. Platforms collect behavioral fuel but lack ethical tanks to store or redirect it. Warnings vanish into corporate fog.  

Historically, tech firms treat harm as an edge case until it becomes a headline. Then they retrofit ethics like spare tires. Compare this to aviation or medicine—fields where near-misses trigger systemic reviews. AI operates on a different highway: one with no guardrails, only speed limits set by PR teams.  

The real failure isn’t detection. It’s the absence of a door between insight and action. Employees sensed danger. Their signal hit a wall of policy inertia.  

Going forward, every AI firm will face this test: Can you act on foresight, or only apologize for hindsight?  
If platforms keep hoarding behavioral data without building response protocols, they become passive accomplices.  
The next warning may arrive too late. Or worse—it may arrive right on time, and still be ignored.

---

## Making frontier cybersecurity capabilities available to defenders - Anthropic

**Link:** https://news.google.com/rss/articles/CBMiYEFVX3lxTFBvaU1YUDA5TzFVT0tfOGtOcUM4ZnZtRkR1WFZFVWlMcjVCUTFOUDZqRzVuTkh1QTRFcTRZQkkyM3JldkxzcjFEdkZPNW16TndPY2JEVW9BSUJpR2o3TFJLaA?oc=5

**Summary:** <a href="https://news.google.com/rss/articles/CBMiYEFVX3lxTFBvaU1YUDA5TzFVT0tfOGtOcUM4ZnZtRkR1WFZFVWlMcjVCUTFOUDZqRzVuTkh1QTRFcTRZQkkyM3JldkxzcjFEdkZPNW16TndPY2JEVW9BSUJpR2o3TFJLaA?oc=5" target="_blank">Making frontier cybersecurity capabilities available to defenders</a>&nbsp;&nbsp;<font color="#6f6f6f">Anthropic</font>

**Swetlana Commentary:**
Anthropic promises to hand “frontier cybersecurity capabilities” to defenders. Not attackers. Just defenders. Convenient.  

The phrase itself is a fog machine. What does “frontier” mean here? AI that finds zero-days faster than humans? Models that mimic adversary behavior at scale? If so, the line between defense and offense blurs like wet ink.  

This isn’t generosity. It’s controlled release. Anthropic retains the steering wheel while offering passengers a map. The real product isn’t protection—it’s influence over who gets to see the road ahead.  

Historically, every “defensive” cyber leap—encryption, intrusion detection, sandboxing—was soon repurposed. Stuxnet used defensive-grade code-signing. NSO’s Pegasus hid in update mechanisms. Tools don’t stay neutral. They migrate toward power.  

Note who’s absent from this rollout: civil society, independent researchers, small firms. The tank has limited capacity. Only certain allies get seats.  

On a scale of 1–10 for transparency, this rates a 2. We’re told what the tool does, not how it decides, who audits it, or when it might flip modes. That silence is structural.  

The future road forks. One path: democratized defense, where red teams and watchdogs access the same AI eyes. The other: a gated highway where only vetted players drive, and everyone else walks in fog.  

Anthropic chose the gate. They call it responsibility. It looks more like curation—with all the control that word implies.

---
